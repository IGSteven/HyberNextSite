// filepath: c:\Steve\dev\next-site-github\HyberNextSite\app\api\ai\generate\route.ts
import { NextRequest, NextResponse } from "next/server";
import OpenAI from 'openai';

// Check if AI generation is enabled in environment variables
const isAIGenerationEnabled = process.env.AI_GENERATION === 'true';
const openaiApiKey = process.env.OPENAI_KEY;
const openaiModel = process.env.OPENAI_MODEL || 'gpt-3.5-turbo';

// Initialize OpenAI client if enabled
const openai = isAIGenerationEnabled && openaiApiKey 
  ? new OpenAI({ apiKey: openaiApiKey })
  : null;

// Function to generate content using OpenAI API
async function generateWithOpenAI(prompt: string): Promise<string> {
  if (!openai) {
    throw new Error('OpenAI client is not initialized. Check API key and AI_GENERATION settings.');
  }
  
  try {
    console.log(`Generating content with OpenAI (${openaiModel}) using prompt:`, prompt);
    
    // Customize system prompt based on content type
    let systemPrompt = 'You are a helpful assistant that generates content for HyberHost, a web hosting company. Write in a professional, clear tone with technical accuracy.';
    
    // Default token limit for most content types
    let maxTokens = 4000; // Increased from 1500 to allow for more complete content
    
    // For title generation, provide more specific formatting instructions
    if (prompt.includes('title')) {
      systemPrompt = 'You are generating titles for a knowledge base article for HyberHost, a web hosting company. Create concise, SEO-friendly titles that start with an appropriate emoji. Keep titles under 60 characters, without Markdown formatting. Example: "ðŸ”’ Securing Your Website with Free SSL Certificates". Base your title on the article content excerpt provided in the prompt.';
      maxTokens = 60; // Keep titles short
    } else if (prompt.includes('excerpt')) {
      systemPrompt += ' Create a concise summary in 1-2 sentences without Markdown formatting.';
      maxTokens = 150; // Reasonable for excerpts
    } else if (prompt.includes('content')) {
      // For full content, use Markdown and allow much longer responses
      systemPrompt = 'You are a technical writer for HyberHost, a web hosting company. Create content that follows the format and instructions provided in the user prompt. Ensure the article is complete and not truncated.';
      maxTokens = 32000; // Maximum possible tokens to ensure complete, comprehensive articles
    } else if (prompt.includes('tags')) {
      systemPrompt = 'You are generating tags for a knowledge base article for HyberHost, a web hosting company. Create highly relevant, precise tags based on the article details provided. Return only a comma-separated list of tags (no other text). Include only the most relevant tags (up to a maximum of 6, but prefer fewer, more precise tags rather than many generic ones). Tags should be concise, specific to web hosting, and helpful for categorization. IMPORTANT: DO NOT include any of the article\'s category names as tags, since those are already used as categories. Focus on specific technical terms and concepts instead.';
      maxTokens = 100; // Short response for tags
    }
    
    const response = await openai.chat.completions.create({
      model: openaiModel,
      messages: [
        {
          role: 'system',
          content: systemPrompt
        },
        {
          role: 'user',
          content: prompt
        }
      ],
      temperature: 0.7,
      max_tokens: maxTokens
    });
    
    // Extract and return the generated content
    const generatedContent = response.choices[0]?.message?.content?.trim() || '';
    if (!generatedContent) {
      throw new Error('No content was generated by the AI model');
    }
    
    // Log the generated content to the server console for debugging
    if (prompt.includes('content')) {
      console.log('\n=== AI GENERATED CONTENT START ===\n');
      console.log(generatedContent);
      console.log('\n=== AI GENERATED CONTENT END ===\n');
    } else {
      console.log('Generated content:', generatedContent);
    }
    
    return generatedContent;
  } catch (error) {
    console.error('Error calling OpenAI API:', error);
    throw new Error('Failed to generate content with OpenAI API');
  }
}

// New function that uses streaming for large content generation (like articles)
async function generateContentWithStreaming(prompt: string): Promise<Response> {
  if (!openai) {
    throw new Error('OpenAI client is not initialized. Check API key and AI_GENERATION settings.');
  }
  
  console.log(`Generating content with OpenAI streaming (${openaiModel}) using prompt:`, prompt);
  
  // Customize system prompt based on content type - focusing on article content
  const systemPrompt = 'You are a technical writer for HyberHost, a web hosting company. Create content that follows the format and instructions provided in the user prompt. Ensure the article is complete and not truncated.';
  
  try {
    const stream = await openai.chat.completions.create({
      model: openaiModel,
      messages: [
        {
          role: 'system',
          content: systemPrompt
        },
        {
          role: 'user',
          content: prompt
        }
      ],
      temperature: 0.7,
      max_tokens: 32000,
      stream: true,
    });
    
    // Create a TransformStream to handle the OpenAI streaming response
    const encoder = new TextEncoder();
    const decoder = new TextDecoder();
    let counter = 0;
    let fullContent = ''; // Store the full content for logging
    
    const transformStream = new TransformStream({
      async transform(chunk, controller) {
        counter++;
        
        if (counter === 1) {
          // Send start of JSON for the first chunk
          controller.enqueue(encoder.encode('{"success":true,"content":"'));
        }
        
        // Process the chunk from OpenAI
        const data = decoder.decode(chunk);
        // Escape quotes and backslashes for JSON compatibility
        const escapedData = data.replace(/\\/g, '\\\\').replace(/"/g, '\\"');
        controller.enqueue(encoder.encode(escapedData));
        
        // Store the original data for logging
        if (data) {
          fullContent += data;
        }
      },
      flush(controller) {
        // Close the JSON object
        controller.enqueue(encoder.encode('"}'));
        
        // Log the complete streamed content to the server console
        console.log('\n=== AI GENERATED STREAMING CONTENT START ===\n');
        console.log(fullContent);
        console.log('\n=== AI GENERATED STREAMING CONTENT END ===\n');
      }
    });
    
    // Use the Web Streams API to handle the response
    return new Response(stream.toReadableStream().pipeThrough(transformStream), {
      headers: {
        'Content-Type': 'application/json',
        'Cache-Control': 'no-cache',
      },
    });
  } catch (error) {
    console.error('Error with streaming content generation:', error);
    return new Response(
      JSON.stringify({ 
        success: false, 
        error: error instanceof Error ? error.message : 'An unknown error occurred' 
      }),
      { 
        status: 500,
        headers: { 'Content-Type': 'application/json' }
      }
    );
  }
}

export async function POST(request: NextRequest) {
  try {
    const { prompt, stream } = await request.json();
    
    if (!prompt) {
      return NextResponse.json(
        { success: false, error: "No prompt provided" },
        { status: 400 }
      );
    }
    
    // Check if AI generation is properly configured
    if (!isAIGenerationEnabled || !openaiApiKey) {
      return NextResponse.json(
        { 
          success: false, 
          error: "AI generation is not configured. Set AI_GENERATION=true and provide OPENAI_KEY in your environment variables." 
        },
        { status: 500 }
      );
    }
    
    // If content is being generated and streaming is requested, use the streaming approach
    if (prompt.includes('content') && stream === true) {
      return generateContentWithStreaming(prompt);
    } 
    
    // Otherwise use standard approach for smaller content
    const content = await generateWithOpenAI(prompt);
    
    return NextResponse.json({
      success: true,
      content,
    });
  } catch (error: any) {
    console.error("Error generating content:", error);
    return NextResponse.json(
      {
        success: false,
        error: error.message || "Failed to generate content",
      },
      { status: 500 }
    );
  }
}